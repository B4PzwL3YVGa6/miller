================================================================
BUGFIXES

:D

================================================================
TOP OF LIST

----------------------------------------------------------------
* implement \0 after all? the regex lib provides it, after all.
  - UT
  - mld:ref:regex update

!! filter/gate into the put DSL: and begin/end.

  o pick good names for eval (or bare-boolean ...)/filter/gate

  o begin/end statements: useful only with out of stream variables (oosrecs)
    - single oosrec? (sum, count)
    - multiple oosrecs? (x.sum, y.count)
    - both? missing leading "name." implies _. or some such ... or, single outrecs with single attrs.
    - output some/all of them at the end, conditionally. not "print" but something like that.
    - allow per-record statements to read/write them.
    - sigil syntax w/ @? or just sigil-free? (@sum vs. sum ...)
    - implement $0 now
  o more:
    - need an unset/clear syntax
    - people will ask for +=, -=, etc.

  o mlr put '
      begin {
        sum = 0;
        count = 0;
        x[1] = 1;
        x[2] = 2;
        emit x[];
        emit sum;
      }
      gate $3 > 0;
      filter $2 =~ "(..)_(...)";
      $left = "\1";
      $right = "\1";
      sum += $3;
      emit sum;
      $3_rsum = sum;
      $y[] = $0;
      end {
        emit sum;
        emit count;
        emit x[];
        emit y[];
      }
    '
  o now: grammar makes array of AST w/ each being assignment or bare-boolean
    - assignment: LHS -> output field name; RHS evaluates to mlrval
    - bare-boolean: null output field name; RHS must evaluate to boolean mlrval
  o next:
    - assignment: LHS -> output field name; RHS evaluates to mlrval
    - bare-boolean: null output field name; RHS must evaluate to boolean mlrval
    - gate: RHS must evaluate to boolean mlrval
    - filter: RHS must evaluate to boolean mlrval
  o new: array of AST being assignment, gate, filter, emit, bare-boolean/newname, begin, end
    - or maybe array of begin nodes, array of mid nodes, array of end nodes
    - assignment: LHS -> output field name; RHS evaluates to mlrval
      > lhs is $0 or oosvar
      > rhs is field name or oosvar or literal
      > want xref[] = $0 kinds of record-from-record assignments
      ? want $0 = xref[] kinds of record-from-record assignments?!?
    - gate: RHS must evaluate to boolean mlrval
    - filter: RHS must evaluate to boolean mlrval
    - emit: RHS must evaluate to lrec (via $0 or oosrec)
    - bare-boolean: expression must evaluate to boolean mlrval
    - begin: each child node is:
      > oosvar-from-oosvar-or-literal assignment
      > emit oosvar or literal
    - end: each child node is:
      > oosvar-from-oosvar-or-literal assignment
      > emit oosvar or literal


  i if / else / begin / end / off-record vars ... not yet (if ever) but think carefully about how not to break the
    (possible) future while implementing the present

  iterates:
  k bare-boolean / filter / gate keywords into the dsl
  ! provide a keyword for bare-boolean
  ! provide a special node type for assignment operator (not just operator)
  ! define behavior for null-valued filter/gate
  ? put -v UTs from /dev/null
  ? filter action-taking within mapper_put/lrec_evaluators + UTs
  ? gate   action-taking within mapper_put/lrec_evaluators + UTs
  ? get rid of put -x and put -t
  ? emit keyword into the DSL
  ? oosrec names into the DSL. disallow assignment-to-keyword (use a hashmap).
  ? begin{} / end{} into the DSL.
  ? begin{} / end{} action-taking within mapper_put:
    > first just echo out something to stub-action-take on emit
    > then populate lrecs

----------------------------------------------------------------
! boolean-eval short-circuiting !
  o lrec_evaluator_alloc_from_b_bb_func is used by && || ^^
  o split out three funcs

* cat/cut langcomps (w/ gh links) -> perf page

* json-flat-to-dkvp filter (python ...)
  - & to the FAQ

* interpolated percentiles

* stats1/stats2 sliding-window feature? and/or with ewma-coefficients (much easier)
  - mean/stddev/var; skew/kurt?
  - linregs; corr/cov?
  ? also, option of weighted stats w/ explicit weights field?
  ? maybe just EWMA with well-known sumw followed by then-chaining. write up the weights if so?

* mld re cross-record stuff is limited to stats1/2 and step
* faqent re nidx output: '$9 = ...' doesn't make it the 9th output field.
* tbin/ok -> cookbook
* faqent why dollar signs in the DSL at all
* debian screenshot
* lrec_evaluators cleanup re strict, redundant statements, etc.
* ruby @ optextdep @ mld; poki+mkman
! mixed-format joins ... make UT cases
* comma-number -- using locale?
* stdin filename keyword for read-from-file-then-tail-f mode (e.g. mlr etc)
  - needs refactor for lrec_reader_alloc callsite
* perf page: (1) redo; (2) note GNU/etc; (3) compare to mawk (http://invisible-island.net/mawk/)
* EOS comments thruout
* valgrind note @ new dev page/section
* join: final sllv_free in destructor (lo-pri)
* anim ref https://github.com/edi9999/path-extractor

* packaging/currency:
  k brew
  ~ netbsd
  k debian
  ? redhat ?
  ? centos ?
  ? other ?

* flight misc: .screenrc -> dotfiles; more dotfile currency
* cump -> one-offs

----------------------------------------------------------------
NARRATIVE INTRO:
* sql example
* logging example
* csv example
* what do these have in common?

----------------------------------------------------------------
COOKBOOK/FAQ/ETC.:

* cookbook:
  - eval stuff from https://github.com/johnkerl/miller/issues/88

    $ mlr --csvlite stats2 -a linreg-pca  -f x,y x
    x_y_pca_m,x_y_pca_b,x_y_pca_n,x_y_pca_quality
    1.030300,0.949250,4,0.999859
    $ mlr --csvlite --odkvp --ofs semicolon stats2 -a linreg-pca  -f x,y x
    x_y_pca_m=1.030300;x_y_pca_b=0.949250;x_y_pca_n=4;x_y_pca_quality=0.999859
    $ eval $(mlr --csvlite --odkvp --ofs semicolon stats2 -a linreg-pca  -f x,y x)
    $ echo $x_y_pca_m
    1.030300

  - hold-and-fit regressor doc: 'then put' for residuals; note avoids two-pass &
    the saving of fit parameters
  - histo w/ min/max is effectively 2-pass (unless you have prior knowledge about the data).
    note count-distinct w/ int() func.
  - two-pass lin/logi reg vs. hold-and-fit.

  - very specific R/mysql/etc inouts

  - polyglottal dkvp/etc production.
  - very specific examples of sed/grep/etc preprocessing to structurize semi-structured data (e.g. logs)

  - checku.dash -> cookbook

* faqents:
  - rsum as proxy for per-record/agg-only mixed output

* other doc besides cookbook & faq:
  - R doc:
    ! xref @ covers x 2
    ! be very clear streaming vs. dataframe -- each has things the other can't do
    ! emph mlr has light stats but for heavyweight analysis use R et al.

* --mmap @ mlr -h
* bus-insurance dev page

================================================================
* ect feature?
  -> maybe better in cookbook ...
  - in1 optional: t (epoch seconds); default systime()
  - in2: nleft
  - in3 optional: target #/field name
  - in optional: -s flag or not
  - out1: etchours
  - out2: etcstamp

  o expose mapper_stats2_alloc
  o expose mapper_cut_alloc
  o encapsulate the following:
    mlr put '$t=systime()' \
      then filter 'NR>4' \
      then  put '$nleft=$target-$n' \
      then stats2 -s -a linreg-pca -f t,nleft \
      then put '$etc= -$t_n_pca_b/$t_n_pca_m; $etcstamp=sec2gmt($etc); $etchours=($etc-systime())/3600.0'

* mlr step -a from-first -f t \
    then cut -o -f t_from_first,ntodo \
    then step -a ewma -d 0.005,0.01,0.1 -o a,b,c -f ntodo \
    then stats2 -s -a linreg-pca -f \
      t_from_first,ntodo,t_from_first,ntodo_ewma_a,t_from_first,ntodo_ewma_b,t_from_first,ntodo_ewma_c \
    then put '
      $ect0 = -$t_from_first_ntodo_pca_b/$t_from_first_ntodo_pca_m;
      $ecta = -$t_from_first_ntodo_ewma_a_pca_b/$t_from_first_ntodo_ewma_a_pca_m;
      $ectb = -$t_from_first_ntodo_ewma_b_pca_b/$t_from_first_ntodo_ewma_b_pca_m;
      $ectc = -$t_from_first_ntodo_ewma_c_pca_b/$t_from_first_ntodo_ewma_c_pca_m
    ' \
    then cut -o -f t_from_first,ect0,ecta,ectb,ectc

----------------------------------------------------------------
* introduce a fourth, padding separator for all formats? (for leading/trailing strip/skip.)
  o allows 'x = 10' in DKVP
  o allows right-justified keys in XTAB

* hold-and-emit fraction?

* statsn covar, ols, logistic: port material from my stats_m/sackmat_m for much of that

* uni/multivariate logistic for ternary & above?

? wiki quickselect ?

* double-check for off-by-one buflen in cline/sline
* hash-collision ifdef instrumentation -> maybe find a better hash function out there
* pprint join?
* lemon in-dir -- cf wiz note
* gprof link with -lc on FreeBSD -- ?

================================================================
UT/REG
* ut cat/X/cat for all X
* ut tac/X/cat for all X
* ut cat/X/tac for all X
* ut tac/X/tac for all X
* ut multi-csv I/O: include --icsvlite --odkvp and --idkvp --ocsv, as well as --csv cases
* ut het-xtab out
* ut modulus operator
* ut make should-fail machinery & use it for null-key dkvp cases.
* ut all mathlib funcs
* ut int/float/string
* ut roundm
* ut join with mixed-format/separator (left vs. right)
* ut join with left/right-prefix

================================================================
DOC

* Note that PCA is better than OLS for roundoff error (sum of squares ...):
  grep red data/multicountdown.txt | head -n 13 | mlr --opprint stats2 -a linreg-ols -f t,count
  grep red data/multicountdown.txt | head -n 14 | mlr --opprint stats2 -a linreg-ols -f t,count

================================================================
IMPROVEMENTS

* run go/d/etc on sprax & include #'s in perf pg, and/or rm xref in the latter & just post xlang perf #'s there
* link to gh/jk/m xlang impls ... and/or cardify their sources :) ... or maybe just link to gh/jk/m xlang dir
* ack c impl has been repeatedly optimized but even the original version (also cutc.c ...) outperforms

* update t1.rb including numeric sort; fix appropriateness of -t=

* more use of restrict pointers ... ?

================================================================
PYTHON
* pgr + stats_m same I/O modules??

================================================================
FYI

Semantic versioning:
Given a version number MAJOR.MINOR.PATCH, increment the:

* MAJOR version when you make incompatible API changes,
* MINOR version when you add functionality in a backwards-compatible manner, and
* PATCH version when you make backwards-compatible bug fixes.

Initial release: https://news.ycombinator.com/item?id=10066742
v2.0.0  release: https://news.ycombinator.com/item?id=10132831

HN FEEDBACKS 2015-08-15 (https://news.ycombinator.com/item?id=10066742).
look-ats:
* cq?
* https://github.com/harelba/q
* https://github.com/google/crush-tools
* https://github.com/BurntSushi/xsv
* https://github.com/pydata/pandas/blob/master/pandas/io/tests/test_parsers.py
* https://drill.apache.org
* https://github.com/dbro/csvquote

https://help.github.com/articles/github-flavored-markdown/

shell: mlr put '$z=$x+$y'
lldb:  run put "\$z=\$x+\$y"

================================================================
git remote add upstream https://github.com/Homebrew/homebrew
git fetch upstream
git rebase upstream/master
shasum -a 256 ../mlr-3.2.2.tar.gz
git diff HEAD^  HEAD
git diff HEAD^2 HEAD

----------------------------------------------------------------
git remote add upstream https://github.com/Homebrew/homebrew
git fetch upstream
git rebase upstream/master
git checkout -r miller-3.2.2
shasum -a 256 ../mlr-3.2.2.tar.gz
git add ...
git commit -m 'miller 3.2.2'
git push --all

----------------------------------------------------------------
Squash commits by:
  brew update
  git checkout $YOUR_BRANCH
  git rebase --interactive origin/master
  mark each commit other than the first as "squash" or "fixup"
  git push -f

http://codeinthehole.com/writing/pull-requests-and-other-good-practices-for-teams-using-github/
