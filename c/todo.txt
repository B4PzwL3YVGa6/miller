================================================================
BUGFIXES

:D

================================================================
TOP OF LIST

----------------------------------------------------------------
* implement \0 after all? the regex lib provides it, after all.
  - UT
  - mld:ref:regex update

* boolean-short-circuit UT w/ regex-captures

----------------------------------------------------------------
!! oosvars/begin/end:

  o next up:
    !! implement multi-emit: emit @a, @b.
    !! work harder on tolerating final semicolon
    !! # comments: replace with spaces from # to EOL/EOS, whichever comes first?
    !  begin{}/end{} into the grammar
    !  accumulate begin/end/main statements within the parser

  o initial sketch: there are two lrecs:
    k one starts with "@" and is out-of-stream.
    k the other starts with "$" and varies per-record.
    k continue the partitioning between LHS name, RHS eval-AST
    k now there are simply two assignment flavors
    k evaluators simply need a reference to two lrecs-with-overlay.
    k this is fine for experimenting.
    ! QUESTION: how far does this get me?? I think I need two-level (oosrecs) in order to put
      things like "stats1 -g foo" firmly into userspace.
    - experiments: what userspace data structures would be needed for:
      > bootstrap?
      > count-distinct?
      > cut?
      > decimate? easy now with NR%10 if not -g; what about with -g?
      > group-by?
      > group-like?
      > having-fields?
      > head?
      > histogram?
      > (rename? reorder?)
      > sample, w/ & w/o -g?
      > stats1 count,sum,mean,stddev,var,skew,kurt; mode; min,max
      > stats2 linregs,r2,corr,cov
      > step
        - delta
        - from-first
        - ratio
        - rsum
        - counter
        - ewma
      > tail
      > top
      > uniq

      mlr put '@a = min(@a, $x); @b = max(@b, $x); end emit @a; end emit @b' ../data/small
      mlr put '
        begin @count=0; begin @sum=0;
        @count=@count+1; @sum=@sum+$x;
        end @mean=@sum/@count; end emit @count; end emit @sum; end emit @mean'
      mlr --opprint put 'begin @ox=0;$d=$x-@ox;@ox=$x' ../data/small
      mlr --opprint put 'begin @ox="no";$d=@ox == "no" ? 1.0 : $x/@ox;@ox=$x' then step -a ratio -f x ../data/small
      mlr --opprint put '$d=$x/@ox;@ox=$x' then step -a ratio -f x ../data/small

  o begin/end statements: useful only with out-of-stream variables (oosvars)
    k so implement oosvars before begin/end ... or implement them with stub-emit 'emit("foo", "bar")'
    k single oosvar? (sum, count)
    k maybe start with per-line prelabels "begin ..." and "end ..." and curly-brace after that?
    - oosrecs? (x.sum, y.count, $x["sum"], $y["count"])
    - both? missing leading "name." implies _. or some such ... or, single outrecs with single attrs.
    - output some/all of them at the end, conditionally. not "print" but something like that.
    k allow per-record statements to read/write them.
    k sigil syntax w/ @? or just sigil-free? (@sum vs. sum ...)
    ? implement $0 now
    k make the oosvars lrecs? lrec-with-typed-overlay? new string-to-mlrval LHM?

    - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
    oosvar-only progress point:

    % mlr put -v '
      begin @count=0;
      begin @sum = 0;
      @count = @count + 1;
      @sum = @sum + $x;
      filter false;
      end @mean = @sum / @count;
      end emit @count;
      end emit @sum;
      end emit @mean
    ' ../data/small

    begin (begin):
        = (oosvar_assignment):
            count (oosvar_name).
            0 (strnum_literal).
    begin (begin):
        = (oosvar_assignment):
            sum (oosvar_name).
            0 (strnum_literal).
    = (oosvar_assignment):
        count (oosvar_name).
        + (operator):
            count (oosvar_name).
            1 (strnum_literal).
    = (oosvar_assignment):
        sum (oosvar_name).
        + (operator):
            sum (oosvar_name).
            x (field_name).
    filter (filter):
        false (boolean_literal).
    end (end):
        = (oosvar_assignment):
            mean (oosvar_name).
            / (operator):
                sum (oosvar_name).
                count (oosvar_name).
    end (end):
        emit (emit):
            count (oosvar_name).
    end (end):
        emit (emit):
            sum (oosvar_name).
    end (end):
        emit (emit):
            mean (oosvar_name).

    count=10
    sum=4.536294
    mean=0.453629
    - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

  o goal: support oosrecs as well as oosvars.
    mlr put '
      begin {
        @sum = 0;
        @count = 0;
        @gsum[] = {};
        @x[1] = 1;
        @x[2] = 2;
        emit @sum;
        emit @x[];
      }
      gate $3 > 0;
      filter $2 =~ "(..)_(...)";
      $left = "\1";
      $right = "\1";
      @sum += $3;
      @gsum[$4] += $3;
      emit @sum;
      $3_rsum = @sum;
      $y[] = $0;
      end {
        emit @sum;
        emit @gsum[];
        emit @count;
        emit @x[];
        emit @y[];
      }
    '

  o now:
    k assignment: LHS -> output field name; RHS evaluates to mlrval
    k bare-boolean: null output field name; RHS must evaluate to boolean mlrval
    k gate: RHS must evaluate to boolean mlrval
    k filter: RHS must evaluate to boolean mlrval
  o new: array of AST being assignment, gate, filter, emit, bare-boolean/newname, begin, end
    - or maybe array of begin nodes, array of mid nodes, array of end nodes within the parser
      (instead of separating out later in mapper_put)
    k oosvar assignment: LHS -> output field name; RHS evaluates to mlrval
      k lhs is $0 or oosvar
      k rhs is field name or oosvar or literal
    k oosrec assignment
      > want xref[] = $0 kinds of record-from-record assignments
      ? want $0 = xref[] kinds of record-from-record assignments?!?
    - gate/filter/bare-booleans must work with oosvars as well as iisrecs
    - emit: RHS must evaluate to lrec (via $0 or oosvar)
    - begin: each child node is:
      > oosvar-from-oosvar-or-literal assignment
      > emit oosvar or literal
    - end: each child node is:
      > oosvar-from-oosvar-or-literal assignment
      > emit oosvar or literal

  o iterates:
    k bare-boolean / filter / gate keywords into the dsl
    k provide a keyword for bare-boolean
    k filter action-taking within mapper_put/lrec_evaluators + UTs
    k gate   action-taking within mapper_put/lrec_evaluators + UTs
    k get rid of put -x and put -t
    k provide a special node type for assignment operator (not just operator)
    ! define/test behavior for null-valued filter/gate
    ? write put -v UTs from /dev/null
    k oosvar names into the DSL.
    - disallow assignment-to-keyword (use a hashmap).
    k emit keyword into the DSL
    ~ begin{} / end{} into the DSL.
    ~ begin{} / end{} action-taking within mapper_put:

  o DSL more:
    - people will ask for an unset/clear syntax
    - people will ask for +=, -=, etc.
    - if / else ... not yet (if ever) but think carefully about how not to break the (possible) future while
      implementing the present

  o replace "null" with "absent" and "uninit"?

----------------------------------------------------------------

* cat/cut langcomps (w/ gh links) -> perf page

* json-flat-to-dkvp filter (python ...)
  - & to the FAQ

* interpolated percentiles

* stats1/stats2 sliding-window feature? and/or with ewma-coefficients (much easier)
  - mean/stddev/var; skew/kurt?
  - linregs; corr/cov?
  ? also, option of weighted stats w/ explicit weights field?
  ? maybe just EWMA with well-known sumw followed by then-chaining. write up the weights if so?

* mld re cross-record stuff is limited to stats1/2 and step
  o this will change with begin/end and oosvars
* faqent re nidx output: '$9 = ...' doesn't make it the 9th output field.
* tbin/ok -> cookbook
* faqent why dollar signs in the DSL at all
* debian screenshot
* lrec_evaluators cleanup re strict, redundant statements, etc.
* ruby @ optextdep @ mld; poki+mkman
! mixed-format joins ... make UT cases
* comma-number -- using locale?
* stdin filename keyword for read-from-file-then-tail-f mode (e.g. mlr etc)
  - needs refactor for lrec_reader_alloc callsite
* perf page: (1) redo; (2) note GNU/etc; (3) compare to mawk (http://invisible-island.net/mawk/)
* EOS comments thruout
* valgrind note @ new dev page/section
* join: final sllv_free in destructor (lo-pri)
* anim ref https://github.com/edi9999/path-extractor

* packaging/currency:
  k brew
  ~ netbsd
  k debian
  ? redhat ?
  ? centos ?
  ? other ?

* flight misc: .screenrc -> dotfiles; more dotfile currency
* cump -> one-offs

----------------------------------------------------------------
NARRATIVE INTRO:
* sql example
* logging example
* csv example
* what do these have in common?

----------------------------------------------------------------
COOKBOOK/FAQ/ETC.:

* cookbook:
  - eval stuff from https://github.com/johnkerl/miller/issues/88

    $ mlr --csvlite stats2 -a linreg-pca  -f x,y x
    x_y_pca_m,x_y_pca_b,x_y_pca_n,x_y_pca_quality
    1.030300,0.949250,4,0.999859
    $ mlr --csvlite --odkvp --ofs semicolon stats2 -a linreg-pca  -f x,y x
    x_y_pca_m=1.030300;x_y_pca_b=0.949250;x_y_pca_n=4;x_y_pca_quality=0.999859
    $ eval $(mlr --csvlite --odkvp --ofs semicolon stats2 -a linreg-pca  -f x,y x)
    $ echo $x_y_pca_m
    1.030300

  - hold-and-fit regressor doc: 'then put' for residuals; note avoids two-pass &
    the saving of fit parameters
  - histo w/ min/max is effectively 2-pass (unless you have prior knowledge about the data).
    note count-distinct w/ int() func.
  - two-pass lin/logi reg vs. hold-and-fit.

  - very specific R/mysql/etc inouts

  - polyglottal dkvp/etc production.
  - very specific examples of sed/grep/etc preprocessing to structurize semi-structured data (e.g. logs)

  - checku.dash -> cookbook

* faqents:
  - rsum as proxy for per-record/agg-only mixed output

* other doc besides cookbook & faq:
  - R doc:
    ! xref @ covers x 2
    ! be very clear streaming vs. dataframe -- each has things the other can't do
    ! emph mlr has light stats but for heavyweight analysis use R et al.

* --mmap @ mlr -h
* bus-insurance dev page

================================================================
* ect feature?
  -> maybe better in cookbook ...
  - in1 optional: t (epoch seconds); default systime()
  - in2: nleft
  - in3 optional: target #/field name
  - in optional: -s flag or not
  - out1: etchours
  - out2: etcstamp

  o expose mapper_stats2_alloc
  o expose mapper_cut_alloc
  o encapsulate the following:
    mlr put '$t=systime()' \
      then filter 'NR>4' \
      then  put '$nleft=$target-$n' \
      then stats2 -s -a linreg-pca -f t,nleft \
      then put '$etc= -$t_n_pca_b/$t_n_pca_m; $etcstamp=sec2gmt($etc); $etchours=($etc-systime())/3600.0'

* mlr step -a from-first -f t \
    then cut -o -f t_from_first,ntodo \
    then step -a ewma -d 0.005,0.01,0.1 -o a,b,c -f ntodo \
    then stats2 -s -a linreg-pca -f \
      t_from_first,ntodo,t_from_first,ntodo_ewma_a,t_from_first,ntodo_ewma_b,t_from_first,ntodo_ewma_c \
    then put '
      $ect0 = -$t_from_first_ntodo_pca_b/$t_from_first_ntodo_pca_m;
      $ecta = -$t_from_first_ntodo_ewma_a_pca_b/$t_from_first_ntodo_ewma_a_pca_m;
      $ectb = -$t_from_first_ntodo_ewma_b_pca_b/$t_from_first_ntodo_ewma_b_pca_m;
      $ectc = -$t_from_first_ntodo_ewma_c_pca_b/$t_from_first_ntodo_ewma_c_pca_m
    ' \
    then cut -o -f t_from_first,ect0,ecta,ectb,ectc

----------------------------------------------------------------
* introduce a fourth, padding separator for all formats? (for leading/trailing strip/skip.)
  o allows 'x = 10' in DKVP
  o allows right-justified keys in XTAB

* hold-and-emit fraction?

* statsn covar, ols, logistic: port material from my stats_m/sackmat_m for much of that

* uni/multivariate logistic for ternary & above?

? wiki quickselect ?

* double-check for off-by-one buflen in cline/sline
* hash-collision ifdef instrumentation -> maybe find a better hash function out there
* pprint join?
* lemon in-dir -- cf wiz note
* gprof link with -lc on FreeBSD -- ?

================================================================
UT/REG
* ut cat/X/cat for all X
* ut tac/X/cat for all X
* ut cat/X/tac for all X
* ut tac/X/tac for all X
* ut multi-csv I/O: include --icsvlite --odkvp and --idkvp --ocsv, as well as --csv cases
* ut het-xtab out
* ut modulus operator
* ut make should-fail machinery & use it for null-key dkvp cases.
* ut all mathlib funcs
* ut int/float/string
* ut roundm
* ut join with mixed-format/separator (left vs. right)
* ut join with left/right-prefix

================================================================
DOC

* Note that PCA is better than OLS for roundoff error (sum of squares ...):
  grep red data/multicountdown.txt | head -n 13 | mlr --opprint stats2 -a linreg-ols -f t,count
  grep red data/multicountdown.txt | head -n 14 | mlr --opprint stats2 -a linreg-ols -f t,count

================================================================
IMPROVEMENTS

* run go/d/etc on sprax & include #'s in perf pg, and/or rm xref in the latter & just post xlang perf #'s there
* link to gh/jk/m xlang impls ... and/or cardify their sources :) ... or maybe just link to gh/jk/m xlang dir
* ack c impl has been repeatedly optimized but even the original version (also cutc.c ...) outperforms

* update t1.rb including numeric sort; fix appropriateness of -t=

* more use of restrict pointers ... ?

================================================================
PYTHON
* pgr + stats_m same I/O modules??

================================================================
FYI

Semantic versioning:
Given a version number MAJOR.MINOR.PATCH, increment the:

* MAJOR version when you make incompatible API changes,
* MINOR version when you add functionality in a backwards-compatible manner, and
* PATCH version when you make backwards-compatible bug fixes.

Initial release: https://news.ycombinator.com/item?id=10066742
v2.0.0  release: https://news.ycombinator.com/item?id=10132831

HN FEEDBACKS 2015-08-15 (https://news.ycombinator.com/item?id=10066742).
look-ats:
* cq?
* https://github.com/harelba/q
* https://github.com/google/crush-tools
* https://github.com/BurntSushi/xsv
* https://github.com/pydata/pandas/blob/master/pandas/io/tests/test_parsers.py
* https://drill.apache.org
* https://github.com/dbro/csvquote

https://help.github.com/articles/github-flavored-markdown/

shell: mlr put '$z=$x+$y'
lldb:  run put "\$z=\$x+\$y"

================================================================
git remote add upstream https://github.com/Homebrew/homebrew
git fetch upstream
git rebase upstream/master
shasum -a 256 ../mlr-3.2.2.tar.gz
git diff HEAD^  HEAD
git diff HEAD^2 HEAD

----------------------------------------------------------------
git remote add upstream https://github.com/Homebrew/homebrew
git fetch upstream
git rebase upstream/master
git checkout -r miller-3.2.2
shasum -a 256 ../mlr-3.2.2.tar.gz
git add ...
git commit -m 'miller 3.2.2'
git push --all

----------------------------------------------------------------
Squash commits by:
  brew update
  git checkout $YOUR_BRANCH
  git rebase --interactive origin/master
  mark each commit other than the first as "squash" or "fixup"
  git push -f

http://codeinthehole.com/writing/pull-requests-and-other-good-practices-for-teams-using-github/
